import streamlit as st
import pandas as pd
import requests
import re
import dns.resolver
import whois
import socket
import random
import string
import time
import io
from PIL import Image
from PIL.ExifTags import TAGS
from PyPDF2 import PdfReader
from fpdf import FPDF
from duckduckgo_search import DDGS
from pyvis.network import Network
from urllib.parse import urlparse
import json

# --- 1. SESSION STATE & STATS ---
if 'stats' not in st.session_state:
    st.session_state.stats = {
        "emails": 0, "breaches": 0, "subdomains": 0, 
        "usernames": 0, "domains": 0, "ips": 0, "certificates": 0
    }
if 'report_results' not in st.session_state:
    st.session_state.report_results = {}

# --- 2. PROFESYONEL RAPORLAMA (PDF) ---
class AmateurOSINTReport(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 15)
        self.cell(0, 10, 'AmateurOSINT Professional Intelligence Report', 0, 1, 'C')
        self.ln(10)
    
    def chapter_title(self, title):
        self.set_font('Arial', 'B', 12)
        self.set_fill_color(230, 230, 230)
        # TÃ¼rkÃ§e karakterleri ASCII'ye dÃ¶nÃ¼ÅŸtÃ¼r
        safe_title = title.encode('ascii', 'ignore').decode('ascii')
        self.cell(0, 10, f"Section: {safe_title}", 0, 1, 'L', True)
        self.ln(5)

    def chapter_body(self, body):
        self.set_font('Arial', '', 10)
        # TÃ¼rkÃ§e karakterleri ASCII'ye dÃ¶nÃ¼ÅŸtÃ¼r
        safe_body = str(body).encode('ascii', 'ignore').decode('ascii')
        self.multi_cell(0, 6, safe_body)
        self.ln()

# --- 3. AMATEUROSINT CORE FRAMEWORK ---
class AmateurOSINT:
    def __init__(self):
        self.headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0"}
        self.email_regex = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        self.domain_regex = r'(?:[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?\.)+[a-z]{2,}'

    # ===== MODÃœLRELÄ° OSINT TÃœRLERÄ° =====

    # 1. USERNAME HUNTER (@username)
    def username_hunter(self, username):
        username = username.replace('@', '').strip()
        platforms = {
            "GitHub": f"https://github.com/{username}",
            "Twitter (X)": f"https://twitter.com/{username}",
            "Instagram": f"https://instagram.com/{username}",
            "Reddit": f"https://www.reddit.com/user/{username}",
            "Medium": f"https://medium.com/@{username}",
            "Steam": f"https://steamcommunity.com/id/{username}",
            "TikTok": f"https://www.tiktok.com/@{username}",
            "YouTube": f"https://www.youtube.com/@{username}",
            "LinkedIn": f"https://linkedin.com/in/{username}",
            "Pinterest": f"https://pinterest.com/{username}",
            "Twitch": f"https://twitch.tv/{username}"
        }
        found = []
        for name, url in platforms.items():
            try:
                res = requests.get(url, timeout=3, headers=self.headers)
                if res.status_code == 200:
                    found.append({"Platform": name, "URL": url, "Status": "FOUND"})
            except: 
                pass
        return found

    # 2. EMAIL HARVESTING (E-posta Toplama)
    def email_harvesting(self, domain):
        """Domain'den baÄŸlantÄ±lÄ± e-postalarÄ± topla"""
        emails = set()
        try:
            with DDGS() as ddgs:
                # E-posta aramasÄ±
                results = list(ddgs.text(f"site:{domain} email OR contact", max_results=10))
                for result in results:
                    found_emails = re.findall(self.email_regex, result['body'])
                    emails.update(found_emails)
                
                # WHOIS'ten e-postalarÄ± Ã§Ä±kar
                try:
                    w = whois.whois(domain)
                    if hasattr(w, 'admin_email'):
                        emails.add(w.admin_email)
                    if hasattr(w, 'tech_email'):
                        emails.add(w.tech_email)
                except:
                    pass
        except:
            pass
        
        return list(emails)

    # 3. SUBDOMAIN ENUMERATION (Alt-domain KeÅŸfi)
    def subdomain_enum(self, domain):
        """AlÄ±na domainleri bul"""
        subdomains = set()
        common_subs = [
            "www", "mail", "ftp", "api", "admin", "test", "dev", "staging",
            "app", "backup", "blog", "news", "shop", "cdn", "git", "auth",
            "vpn", "ssl", "portal", "forum", "support", "help", "status"
        ]
        
        for sub in common_subs:
            try:
                hostname = f"{sub}.{domain}"
                ip = socket.gethostbyname(hostname)
                subdomains.add(frozenset([("Subdomain", hostname), ("IP", ip)]))
            except:
                pass
        
        # DuckDuckGo ile araÅŸtÄ±r
        try:
            with DDGS() as ddgs:
                results = list(ddgs.text(f"site:{domain}", max_results=5))
                for r in results:
                    urls = re.findall(r'https?://([^/]+)', r['body'])
                    for url in urls:
                        if domain in url:
                            subdomains.add(frozenset([("Subdomain", url), ("IP", "N/A")]))
        except:
            pass
        
        return [dict(s) for s in subdomains]

    # 4. BREACH SEARCH (SÄ±zÄ±ntÄ± KontrolÃ¼)
    def breach_check(self, query):
        findings = []
        dorks = [
            f"site:pastebin.com '{query}'", 
            f"site:github.com '{query}' password",
            f"site:pastebin.com {query}",
            f"'{query}' breach OR leak OR exposed"
        ]
        try:
            with DDGS() as ddgs:
                for dork in dorks:
                    results = ddgs.text(dork, max_results=3)
                    for r in results:
                        findings.append({
                            "Source": "Potential Leak",
                            "URL": r['href'],
                            "Context": r['body'][:150]
                        })
            return findings
        except:
            return []

    # 5. WHOIS DETAYLI (WHOIS Analizi)
    def whois_lookup(self, domain):
        """DetaylÄ± WHOIS bilgisi al"""
        try:
            w = whois.whois(domain)
            return {
                "Domain": w.domain,
                "Registrar": getattr(w, 'registrar', 'N/A'),
                "Creation Date": str(getattr(w, 'creation_date', 'N/A')),
                "Expiration Date": str(getattr(w, 'expiration_date', 'N/A')),
                "Admin": getattr(w, 'admin_name', 'N/A'),
                "Admin Email": getattr(w, 'admin_email', 'N/A'),
                "Tech Contact": getattr(w, 'tech_name', 'N/A'),
                "Nameservers": getattr(w, 'name_servers', 'N/A')
            }
        except Exception as e:
            return {"Error": str(e)}

    # 6. DNS RECORDS (DNS KayÄ±tlarÄ±)
    def dns_records(self, domain):
        """TÃ¼m DNS kayÄ±tlarÄ±nÄ± al"""
        records = {}
        record_types = ['A', 'MX', 'TXT', 'NS', 'CNAME', 'SOA']
        
        for rtype in record_types:
            try:
                resolver = dns.resolver.Resolver()
                resolver.timeout = 5
                answer = resolver.resolve(domain, rtype)
                records[rtype] = [str(r) for r in answer]
            except:
                pass
        
        return records

    # 7. REVERSE DNS LOOKUP (Ters DNS)
    def reverse_dns(self, ip):
        """IP adresinin reverse DNS'ini al"""
        try:
            hostname = socket.gethostbyaddr(ip)
            return {"IP": ip, "Hostname": hostname[0], "Aliases": hostname[1]}
        except:
            return {"IP": ip, "Hostname": "N/A", "Error": "Reverse DNS baÅŸarÄ±sÄ±z"}

    # 8. GEO-IP LOCALIZATION (CoÄŸrafi Konum)
    def geo_ip(self, target):
        try:
            ip = socket.gethostbyname(target)
            res = requests.get(f"http://ip-api.com/json/{ip}", timeout=5).json()
            return res if res.get('status') == 'success' else None
        except:
            return None

    # 9. WEB ARCHIVE (Wayback Machine)
    def web_archive(self, url):
        """Wayback Machine'den sayfa tarihÃ§esi al"""
        try:
            domain = urlparse(url).netloc if "://" in url else url
            res = requests.get(f"https://archive.org/wayback/available?url={domain}", timeout=5).json()
            if res.get('archived_snapshots'):
                snapshots = res['archived_snapshots']
                if 'closest' in snapshots:
                    return {
                        "URL": snapshots['closest']['url'],
                        "Timestamp": snapshots['closest']['timestamp'],
                        "Status": snapshots['closest']['status']
                    }
            return {"Status": "No archives found"}
        except:
            return {"Error": "Archive sorgusu baÅŸarÄ±sÄ±z"}

    # 10. SSL CERTIFICATE SEARCH (SSL SertifikasÄ±)
    def ssl_search(self, domain):
        """crt.sh Ã¼zerinden SSL sertifikalarÄ±nÄ± bul"""
        try:
            res = requests.get(f"https://crt.sh/?q={domain}&output=json", timeout=10).json()
            certs = []
            for cert in res[:10]:  # Ä°lk 10'u al
                certs.append({
                    "Common Name": cert.get('common_name', 'N/A'),
                    "Issuer": cert.get('issuer_name', 'N/A'),
                    "Issued": cert.get('entry_timestamp', 'N/A')
                })
            return certs
        except:
            return []

    # 11. ASN & IP RANGE LOOKUP (ASN AramasÄ±)
    def asn_lookup(self, domain_or_ip):
        """ASN ve IP range bilgisi al"""
        try:
            try:
                ip = socket.gethostbyname(domain_or_ip)
            except:
                ip = domain_or_ip
            
            res = requests.get(f"http://ip-api.com/json/{ip}?fields=asn", timeout=5).json()
            if res.get('status') == 'success':
                return {
                    "IP": ip,
                    "ASN": res.get('asn', 'N/A'),
                    "ISP": res.get('isp', 'N/A'),
                    "Organization": res.get('org', 'N/A')
                }
            return {"Error": "ASN lookup baÅŸarÄ±sÄ±z"}
        except:
            return {"Error": "ASN lookup baÅŸarÄ±sÄ±z"}

    # 12. METADATA EXTRACTION (Meta Veri Ã‡Ä±karma - Exiftool benzeri)
    def extract_metadata(self, file):
        """Exiftool gibi detaylÄ± metadata Ã§Ä±karma"""
        meta = {}
        file_info = {}
        
        try:
            # Dosya temel bilgileri
            file_info["File Name"] = file.name
            file_info["File Size"] = f"{file.size / 1024:.2f} KB"
            file_info["File Type"] = file.type
            
            if file.type.startswith("image"):
                try:
                    img = Image.open(file)
                    
                    # === TEMEL RESÄ°M BÄ°LGÄ°SÄ° ===
                    meta["ğŸ“· IMAGE INFORMATION"] = {
                        "Format": img.format or "Unknown",
                        "Mode": img.mode,
                        "Width": img.width,
                        "Height": img.height,
                        "Size": f"{img.width}x{img.height}",
                        "DPI": img.info.get('dpi', 'N/A'),
                        "Is Animated": getattr(img, 'is_animated', False),
                        "Frames": img.n_frames if hasattr(img, 'n_frames') else 1
                    }
                    
                    # === EXIF VERÄ°LERÄ° ===
                    exif_dict = {}
                    try:
                        exif = img.getexif()
                        if exif:
                            for tag, value in exif.items():
                                try:
                                    decoded = TAGS.get(tag, f"Tag {tag}")
                                    value_str = str(value)[:100]  # Uzun deÄŸerleri kes
                                    exif_dict[decoded] = value_str
                                except:
                                    exif_dict[f"Tag {tag}"] = str(value)[:100]
                    except:
                        pass
                    
                    if exif_dict:
                        meta["ğŸ“¸ EXIF DATA"] = exif_dict
                    
                    # === RESÄ°M Ã–ZELLIKLERI ===
                    meta["ğŸ¨ IMAGE PROPERTIES"] = {
                        "Color Space": img.mode,
                        "Has Palette": hasattr(img, 'palette'),
                        "Has Transparency": 'transparency' in img.info,
                        "Compression": img.info.get('compression', 'N/A'),
                        "Format Description": img.info.get('description', 'N/A')
                    }
                    
                except Exception as e:
                    meta["Image Processing Error"] = str(e)
                    
            elif file.type == "application/pdf":
                try:
                    reader = PdfReader(file)
                    
                    # === PDF METADATA ===
                    pdf_meta = {}
                    if reader.metadata:
                        for k, v in reader.metadata.items():
                            pdf_meta[k.lstrip('/')] = str(v)
                    
                    if pdf_meta:
                        meta["ğŸ“„ PDF METADATA"] = pdf_meta
                    
                    # === PDF BÄ°LGÄ°SÄ° ===
                    meta["ğŸ“‹ PDF INFORMATION"] = {
                        "Total Pages": len(reader.pages),
                        "Author": reader.metadata.get('/Author', 'N/A') if reader.metadata else 'N/A',
                        "Title": reader.metadata.get('/Title', 'N/A') if reader.metadata else 'N/A',
                        "Subject": reader.metadata.get('/Subject', 'N/A') if reader.metadata else 'N/A',
                        "Creator": reader.metadata.get('/Creator', 'N/A') if reader.metadata else 'N/A',
                        "Producer": reader.metadata.get('/Producer', 'N/A') if reader.metadata else 'N/A',
                        "Creation Date": str(reader.metadata.get('/CreationDate', 'N/A')) if reader.metadata else 'N/A',
                        "Modification Date": str(reader.metadata.get('/ModDate', 'N/A')) if reader.metadata else 'N/A',
                        "Encrypted": reader.is_encrypted
                    }
                    
                    # === Ä°LK SAYFA BÄ°LGÄ°SÄ° ===
                    if len(reader.pages) > 0:
                        first_page = reader.pages[0]
                        page_info = {
                            "Width": first_page.mediabox.width,
                            "Height": first_page.mediabox.height,
                            "Rotation": first_page.get("/Rotate", 0),
                            "Resources": list(first_page.resources.keys()) if first_page.resources else []
                        }
                        meta["ğŸ“– FIRST PAGE"] = page_info
                    
                except Exception as e:
                    meta["PDF Processing Error"] = str(e)
            
            # === DOSYA BÄ°LGÄ°SÄ° ===
            meta["ğŸ“ FILE INFORMATION"] = file_info
            
        except Exception as e:
            meta["Critical Error"] = str(e)
        
        return meta

    # 13. PASSWORD STRENGTH (Åifre GÃ¼cÃ¼)
    def check_password(self, pwd):
        score = 0
        if len(pwd) >= 12: score += 2
        if any(c.isupper() for c in pwd): score += 1
        if any(c.isdigit() for c in pwd): score += 1
        if any(c in string.punctuation for c in pwd): score += 1
        return "Ã‡ok GÃ¼Ã§lÃ¼" if score >= 4 else "Orta" if score >= 2 else "ZayÄ±f"

# --- 4. ARAYÃœZ TASARIMI ---
st.set_page_config(page_title="AmateurOSINT Hub", layout="wide", page_icon="ğŸ”")
osint = AmateurOSINT()

st.title("ğŸ” AmateurOSINT Professional Hub")
st.markdown("*Profesyonel OSINT AraÅŸtÄ±rmasÄ± Ä°Ã§in KapsamlÄ± Platform*")

# --- VISUAL DASHBOARD ---
st.markdown("### ğŸ“Š Operasyonel Dashboard")
col1, col2, col3, col4, col5, col6 = st.columns(6)
col1.metric("ğŸ‘¤ Usernames", st.session_state.stats["usernames"])
col2.metric("âš ï¸ Breaches", st.session_state.stats["breaches"])
col3.metric("ğŸŒ Subdomains", st.session_state.stats["subdomains"])
col4.metric("ğŸ“§ Emails", st.session_state.stats["emails"])
col5.metric("ğŸ¢ Domains", st.session_state.stats["domains"])
col6.metric("ğŸ“œ Certificates", st.session_state.stats["certificates"])
st.divider()

# --- SIDEBAR MENU ---
menu = st.sidebar.selectbox("ğŸš€ OSINT ModÃ¼lleri", [
    "ğŸ” Identity & Social Mapping",
    "ğŸ“§ Email Harvesting",
    "ğŸŒ Domain Intelligence",
    "âš ï¸ Breach Detection",
    "ğŸ›¡ï¸ Infrastructure Reconnaissance",
    "ğŸ“œ SSL Certificates",
    "ğŸ–¼ï¸ Metadata Analysis",
    "ğŸ“ Geo-Intelligence",
    "ğŸ” Password Analysis",
    "ğŸ“„ Generate Report"
])

# ===== MODÃœL 1: IDENTITY & SOCIAL MAPPING =====
if menu == "ğŸ” Identity & Social Mapping":
    st.header("ğŸ‘¤ Kimlik ve Sosyal Medya HaritasÄ±")
    st.markdown("Hedef kiÅŸinin sosyal medya ve Ã§evrimiÃ§i varlÄ±ÄŸÄ±nÄ± harita alÄ±r.")
    
    target = st.text_input("Hedef (Ä°sim, E-posta veya @username)", placeholder="@macallantheroot")
    
    col_a, col_b, col_c = st.columns(3)
    with col_a:
        if st.button("ğŸ” Sosyal Medya TaramasÄ±", use_container_width=True):
            with st.spinner("Sosyal aÄŸlar taranÄ±yor..."):
                hits = osint.username_hunter(target)
                if hits:
                    st.session_state.stats["usernames"] += len(hits)
                    st.success(f"âœ… {len(hits)} profil bulundu!")
                    st.dataframe(pd.DataFrame(hits), use_container_width=True)
                    st.session_state.report_results['Social Media Profiles'] = hits
                else:
                    st.warning("âŒ EÅŸleÅŸme bulunamadÄ±.")
    
    with col_b:
        if st.button("ğŸŒ Web Ä°zlerini Ara", use_container_width=True):
            with st.spinner("Web taranÄ±yor..."):
                try:
                    with DDGS() as ddgs:
                        results = list(ddgs.text(target, max_results=5))
                    if results:
                        st.success(f"âœ… {len(results)} sonuÃ§ bulundu!")
                        for idx, r in enumerate(results, 1):
                            st.write(f"{idx}. **{r.get('title', 'N/A')}**")
                            st.caption(r.get('href', 'N/A'))
                        st.session_state.report_results['Web Search'] = results
                    else:
                        st.info("SonuÃ§ bulunamadÄ±.")
                except Exception as e:
                    st.error(f"Hata: {str(e)}")
    
    with col_c:
        if st.button("ğŸ“Š KiÅŸi Ã–zeti", use_container_width=True):
            st.info("Web aramasÄ± ve sosyal medya verilerini birleÅŸtirerek kiÅŸi profili oluÅŸtur.")

# ===== MODÃœL 2: EMAIL HARVESTING =====
elif menu == "ğŸ“§ Email Harvesting":
    st.header("ğŸ“§ E-posta Toplama ve Validasyon")
    st.markdown("Hedef domain ile iliÅŸkili tÃ¼m e-posta adreslerini keÅŸfet.")
    
    domain = st.text_input("Hedef Domain", placeholder="example.com")
    
    col_x, col_y = st.columns(2)
    with col_x:
        if st.button("ğŸ” E-posta Ara", use_container_width=True):
            with st.spinner("E-postalar toplanÄ±yor..."):
                emails = osint.email_harvesting(domain)
                if emails:
                    st.session_state.stats["emails"] += len(emails)
                    st.success(f"âœ… {len(emails)} e-posta bulundu!")
                    for email in emails:
                        st.write(f"ğŸ“§ `{email}`")
                    st.session_state.report_results['Emails Found'] = emails
                else:
                    st.warning("âŒ E-posta bulunamadÄ±.")
    
    with col_y:
        if st.button("ğŸ” WHOIS E-postalarÄ±", use_container_width=True):
            with st.spinner("WHOIS sorgulanÄ±yor..."):
                emails = osint.email_harvesting(domain)
                whois_data = osint.whois_lookup(domain)
                if whois_data.get('Admin Email'):
                    st.success(f"âœ… WHOIS verisi bulundu!")
                    st.json(whois_data)
                    st.session_state.report_results['WHOIS Data'] = whois_data

# ===== MODÃœL 3: DOMAIN INTELLIGENCE =====
elif menu == "ğŸŒ Domain Intelligence":
    st.header("ğŸŒ Domain Ä°stihbaratÄ± ve AltyapÄ± Analizi")
    st.markdown("Domain, DNS, WHOIS ve altyapÄ± bilgilerini eksiksiz analiz et.")
    
    dom = st.text_input("Hedef Domain", placeholder="example.com")
    
    tabs = st.tabs(["WHOIS", "DNS Records", "Subdomains", "ASN Info"])
    
    with tabs[0]:
        if st.button("ğŸ“‹ WHOIS Sorgusu"):
            with st.spinner("WHOIS verileri alÄ±nÄ±yor..."):
                whois_data = osint.whois_lookup(dom)
                st.session_state.stats["domains"] += 1
                st.json(whois_data)
                st.session_state.report_results['WHOIS Analysis'] = whois_data
    
    with tabs[1]:
        if st.button("ğŸ“¡ DNS KayÄ±tlarÄ±nÄ± GÃ¶ster"):
            with st.spinner("DNS kayÄ±tlarÄ± alÄ±nÄ±yor..."):
                dns_data = osint.dns_records(dom)
                if dns_data:
                    st.success(f"âœ… {len(dns_data)} DNS kaydÄ± bulundu!")
                    st.json(dns_data)
                    st.session_state.report_results['DNS Records'] = dns_data
                else:
                    st.warning("DNS kayÄ±tlarÄ± alÄ±namadÄ±.")
    
    with tabs[2]:
        if st.button("ğŸ”— Alt-domainleri Tarama"):
            with st.spinner("Alt-domainler taranÄ±yor..."):
                subs = osint.subdomain_enum(dom)
                if subs:
                    st.session_state.stats["subdomains"] += len(subs)
                    st.success(f"âœ… {len(subs)} alt-domain bulundu!")
                    st.dataframe(pd.DataFrame(subs), use_container_width=True)
                    st.session_state.report_results['Subdomains'] = subs
    
    with tabs[3]:
        if st.button("ğŸ¢ ASN Bilgisi"):
            with st.spinner("ASN sorgulanÄ±yor..."):
                asn = osint.asn_lookup(dom)
                st.json(asn)
                st.session_state.report_results['ASN Lookup'] = asn

# ===== MODÃœL 4: BREACH DETECTION =====
elif menu == "âš ï¸ Breach Detection":
    st.header("âš ï¸ SÄ±zÄ±ntÄ± ve Dark Web KontrolÃ¼")
    st.markdown("Hedefin veri ihlali veya sÄ±zÄ±ntÄ±sÄ±nda olup olmadÄ±ÄŸÄ±nÄ± kontrol et.")
    
    query = st.text_input("E-posta veya Domain", placeholder="target@example.com")
    
    if st.button("ğŸ” SÄ±zÄ±ntÄ± TaramasÄ±", use_container_width=True):
        with st.spinner("Dark Web ve sÄ±zÄ±ntÄ± kaynaklarÄ± taranÄ±yor..."):
            breaches = osint.breach_check(query)
            if breaches:
                st.session_state.stats["breaches"] += len(breaches)
                st.error(f"ğŸš¨ KRÄ°TÄ°K: {len(breaches)} adet olasÄ± sÄ±zÄ±ntÄ± bulundu!")
                df = pd.DataFrame(breaches)
                st.dataframe(df, use_container_width=True)
                st.session_state.report_results['Breach Analysis'] = breaches
            else:
                st.success("âœ… Temiz: SÄ±zÄ±ntÄ± izine rastlanmadÄ±.")

# ===== MODÃœL 5: INFRASTRUCTURE RECONNAISSANCE =====
elif menu == "ğŸ›¡ï¸ Infrastructure Reconnaissance":
    st.header("ğŸ›¡ï¸ AltyapÄ± KeÅŸfi ve Ters DNS")
    st.markdown("IP adresinin sahibi, reverse DNS ve lokasyon bilgisi.")
    
    ip_or_domain = st.text_input("IP Adresi veya Domain", placeholder="8.8.8.8 veya example.com")
    
    tabs = st.tabs(["Ters DNS", "Geo-IP", "Web Archive"])
    
    with tabs[0]:
        if st.button("ğŸ”„ Reverse DNS Sorgusu"):
            with st.spinner("Reverse DNS sorgulanÄ±yor..."):
                try:
                    ip = socket.gethostbyname(ip_or_domain)
                except:
                    ip = ip_or_domain
                
                rev_dns = osint.reverse_dns(ip)
                st.json(rev_dns)
                st.session_state.report_results['Reverse DNS'] = rev_dns
    
    with tabs[1]:
        if st.button("ğŸ“ Geo-IP HaritasÄ±"):
            with st.spinner("Konum bilgisi alÄ±nÄ±yor..."):
                geo = osint.geo_ip(ip_or_domain)
                if geo and 'lat' in geo:
                    st.success("âœ… Konum bulundu!")
                    st.map(pd.DataFrame({'lat': [geo['lat']], 'lon': [geo['lon']]}))
                    st.json(geo)
                    st.session_state.report_results['Geo-Location'] = geo
                else:
                    st.error("âŒ Konum bilgisi alÄ±namadÄ±.")
    
    with tabs[2]:
        if st.button("ğŸ“œ Wayback Machine ArÅŸivi"):
            with st.spinner("Web Archive sorgulanÄ±yor..."):
                archive = osint.web_archive(ip_or_domain)
                st.json(archive)
                st.session_state.report_results['Web Archive'] = archive

# ===== MODÃœL 6: SSL CERTIFICATES =====
elif menu == "ğŸ“œ SSL Certificates":
    st.header("ğŸ“œ SSL SertifikasÄ± Analizi")
    st.markdown("Domain'in SSL sertifikalarÄ± ve tarihÃ§esini gÃ¶rÃ¼ntÃ¼le.")
    
    cert_domain = st.text_input("Hedef Domain", placeholder="*.example.com veya example.com")
    
    if st.button("ğŸ” SSL SertifikalarÄ±nÄ± Ara", use_container_width=True):
        with st.spinner("SSL sertifikalarÄ± aranÄ±yor..."):
            certs = osint.ssl_search(cert_domain)
            if certs:
                st.session_state.stats["certificates"] += len(certs)
                st.success(f"âœ… {len(certs)} sertifika bulundu!")
                st.dataframe(pd.DataFrame(certs), use_container_width=True)
                st.session_state.report_results['SSL Certificates'] = certs
            else:
                st.warning("âŒ Sertifika bulunamadÄ±.")

# ===== MODÃœL 7: METADATA ANALYSIS =====
elif menu == "ğŸ–¼ï¸ Metadata Analysis":
    st.header("ğŸ–¼ï¸ Dosya Meta Veri Analizi (Exiftool benzeri)")
    st.markdown("Resim veya PDF dosyalarÄ±ndan detaylÄ± ve gizli bilgi Ã§Ä±kart. Exiftool benzeri kapsamlÄ± analiz.")
    
    f = st.file_uploader("Resim veya PDF YÃ¼kle", type=["jpg", "jpeg", "png", "gif", "bmp", "tiff", "pdf"])
    if f:
        with st.spinner("Meta veriler derinlemesine analiz ediliyor..."):
            meta = osint.extract_metadata(f)
            if meta:
                st.success("âœ… Dosya analiz tamamlandÄ±!")
                
                # Kategoriye gÃ¶re gÃ¶ster
                tabs = st.tabs(["ğŸ“Š TÃ¼m Veriler", "ğŸ“ Dosya Bilgisi", "ğŸ“¸ EXIF/PDF Meta", "ğŸ¨ Ã–zellikler"])
                
                with tabs[0]:
                    st.json(meta)
                
                with tabs[1]:
                    if "ğŸ“ FILE INFORMATION" in meta:
                        st.subheader("ğŸ“ Dosya Bilgisi")
                        file_info = meta["ğŸ“ FILE INFORMATION"]
                        col1, col2, col3 = st.columns(3)
                        col1.metric("Dosya AdÄ±", file_info.get("File Name", "N/A"))
                        col2.metric("Boyut", file_info.get("File Size", "N/A"))
                        col3.metric("Tip", file_info.get("File Type", "N/A"))
                
                with tabs[2]:
                    if "ğŸ“¸ EXIF DATA" in meta:
                        st.subheader("ğŸ“¸ EXIF Verileri")
                        exif = meta["ğŸ“¸ EXIF DATA"]
                        for key, value in exif.items():
                            st.write(f"**{key}:** `{value}`")
                    elif "ğŸ“„ PDF METADATA" in meta:
                        st.subheader("ğŸ“„ PDF Metadata")
                        pdf_meta = meta["ğŸ“„ PDF METADATA"]
                        for key, value in pdf_meta.items():
                            st.write(f"**{key}:** `{value}`")
                
                with tabs[3]:
                    if "ğŸ¨ IMAGE PROPERTIES" in meta:
                        st.subheader("ğŸ¨ Resim Ã–zellikleri")
                        props = meta["ğŸ¨ IMAGE PROPERTIES"]
                        for key, value in props.items():
                            st.write(f"**{key}:** `{value}`")
                    elif "ğŸ“· IMAGE INFORMATION" in meta:
                        st.subheader("ğŸ“· Resim Bilgisi")
                        img_info = meta["ğŸ“· IMAGE INFORMATION"]
                        col1, col2, col3, col4 = st.columns(4)
                        col1.metric("Format", img_info.get("Format", "N/A"))
                        col2.metric("Boyut", img_info.get("Size", "N/A"))
                        col3.metric("DPI", str(img_info.get("DPI", "N/A")))
                        col4.metric("Mode", img_info.get("Mode", "N/A"))
                
                st.session_state.report_results['Metadata Analysis'] = meta
            else:
                st.warning("âš ï¸ Dosya okunamadÄ± veya metadata Ã§Ä±karÄ±lamadÄ±.")

# ===== MODÃœL 8: GEO-INTELLIGENCE =====
elif menu == "ğŸ“ Geo-Intelligence":
    st.header("ğŸ“ CoÄŸrafi Konum Ä°stihbaratÄ±")
    st.markdown("IP veya domain'in coÄŸrafi konumunu harita Ã¼zerinde gÃ¶ster.")
    
    geo_target = st.text_input("IP veya Domain", placeholder="8.8.8.8 veya google.com")
    
    if st.button("ğŸ—ºï¸ Haritada GÃ¶ster", use_container_width=True):
        with st.spinner("Konum verisi yÃ¼kleniyor..."):
            geo = osint.geo_ip(geo_target)
            if geo and 'lat' in geo:
                st.success("âœ… Konum bulundu!")
                st.map(pd.DataFrame({'lat': [geo['lat']], 'lon': [geo['lon']]}))
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Åehir", geo.get('city', 'N/A'))
                    st.metric("Ãœlke", geo.get('country', 'N/A'))
                with col2:
                    st.metric("ISP", geo.get('isp', 'N/A'))
                    st.metric("Enlem", geo.get('lat', 'N/A'))
                st.json(geo)
                st.session_state.report_results['Geo-Location'] = geo
            else:
                st.error("âŒ Konum bilgisi alÄ±namadÄ±.")

# ===== MODÃœL 9: PASSWORD ANALYSIS =====
elif menu == "ğŸ” Password Analysis":
    st.header("ğŸ” Åifre GÃ¼venlik Analizi")
    st.markdown("Åifre gÃ¼cÃ¼nÃ¼ analiz et ve iyileÅŸtirme Ã¶nerileri al.")
    
    pwd_in = st.text_input("Analiz Edilecek Åifre", type="password")
    if pwd_in:
        strength = osint.check_password(pwd_in)
        
        col1, col2 = st.columns(2)
        with col1:
            if strength == "Ã‡ok GÃ¼Ã§lÃ¼":
                st.success(f"ğŸŸ¢ {strength}")
            elif strength == "Orta":
                st.warning(f"ğŸŸ¡ {strength}")
            else:
                st.error(f"ğŸ”´ {strength}")
        with col2:
            st.metric("Uzunluk", len(pwd_in))
        
        st.session_state.report_results['Password Strength'] = {
            "Strength": strength,
            "Length": len(pwd_in)
        }

# ===== MODÃœL 10: GENERATE REPORT =====
elif menu == "ğŸ“„ Generate Report":
    st.header("ğŸ“„ Profesyonel OSINT Raporu OluÅŸtur")
    st.markdown("TÃ¼m topladÄ±ÄŸÄ±nÄ±z verileri profesyonel PDF raporuna dÃ¶nÃ¼ÅŸtÃ¼r.")
    
    if not st.session_state.report_results:
        st.warning("âš ï¸ VeritabanÄ± boÅŸ! Ã–nce diÄŸer modÃ¼llerde tarama yapÄ±n.")
    else:
        st.info(f"ğŸ“Š {len(st.session_state.report_results)} bÃ¶lÃ¼m verileri var.")
        
        if st.button("ğŸ“¥ PDF Raporunu OluÅŸtur ve Ä°ndir", use_container_width=True):
            with st.spinner("Rapor oluÅŸturuluyor..."):
                try:
                    pdf = AmateurOSINTReport()
                    pdf.add_page()
                    
                    for k, v in st.session_state.report_results.items():
                        pdf.chapter_title(k)
                        pdf.chapter_body(str(v))
                    
                    # PDF'yi UTF-8 ile gÃ¼venli ÅŸekilde oluÅŸtur
                    pdf_bytes = pdf.output(dest='S')
                    if isinstance(pdf_bytes, str):
                        pdf_bytes = pdf_bytes.encode('utf-8', 'ignore')
                    
                    st.success("âœ… Rapor hazÄ±r!")
                    st.download_button(
                        "ğŸ“¥ PDF Raporunu Ä°ndir",
                        pdf_bytes,
                        "AmateurOSINT_Report.pdf",
                        "application/pdf",
                        use_container_width=True
                    )
                except Exception as e:
                    st.error(f"âŒ Rapor oluÅŸturulurken hata: {str(e)}")
        
        if st.button("ğŸ—‘ï¸ Verileri Temizle", use_container_width=True):
            st.session_state.report_results.clear()
            st.rerun()

# --- FOOTER ---
st.divider()
st.markdown("**AmateurOSINT v1.0** | Etik OSINT AraÅŸtÄ±rmasÄ± Platformu | *YalnÄ±zca yasal amaÃ§lar iÃ§in kullanÄ±n* |  **github.com/macallantheroot/AmateurOSINT**")
